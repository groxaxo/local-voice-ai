services:
  kokoro:
    build:
      context: ./inference/kokoro
    ports:
      - "8880:8880"
    networks:
      - agent_network

  soprano:
    build:
      context: ./inference/soprano
    volumes:
      - soprano-data:/root/.cache/huggingface
    ports:
      - "8890:8000"
    networks:
      - agent_network

  livekit:
    image: livekit/livekit-server:latest
    ports:
      - "7880:7880"
      - "7881:7881"
    command: --dev --bind "0.0.0.0"
    networks:
      - agent_network

  whisper:
    build:
      context: ./inference/whisper
    volumes:
      - whisper-data:/data
    environment:
      - VOXBOX_HF_REPO_ID=${VOXBOX_HF_REPO_ID:-Systran/faster-whisper-small}
      - VOXBOX_DEVICE=${VOXBOX_DEVICE:-cpu}
      - DATA_DIR=/data
    ports:
      - "11435:80"
    networks:
      - agent_network

  parakeet:
    build:
      context: ./inference/parakeet
    volumes:
      - parakeet-data:/root/.cache
    environment:
      - PARAKEET_MODEL=${PARAKEET_MODEL:-nvidia/parakeet-tdt-0.6b-v2}
    ports:
      - "8015:8015"
    networks:
      - agent_network
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:8015/v1/models > /dev/null"]
      interval: 15s
      timeout: 10s
      retries: 20
      start_period: 120s

  vllm:
    image: vllm/vllm-openai:latest
    command:
      - --model
      - "${VLLM_MODEL:-ISTA-DASLab/gemma-3-27b-it-GPTQ-4b-128g}"
      - --served-model-name
      - "${VLLM_MODEL_ALIAS:-gemma-3-27b}"
      - --host
      - "0.0.0.0"
      - --port
      - "8000"
      - --max-model-len
      - "${VLLM_MAX_MODEL_LEN:-4096}"
      - --gpu-memory-utilization
      - "${VLLM_GPU_MEMORY_UTILIZATION:-0.90}"
      - --dtype
      - auto
      - --enforce-eager
    ports:
      - "${VLLM_HOST_PORT:-8000}:8000"
    volumes:
      - vllm-data:/root/.cache/huggingface
    environment:
      - HF_TOKEN=${HF_TOKEN:-}
    ipc: host
    networks:
      - agent_network
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:8000/v1/models > /dev/null"]
      interval: 15s
      timeout: 10s
      retries: 40
      start_period: 120s

  livekit_agent:
    build:
      context: ./livekit_agent
    env_file:
      - .env
    environment:
      - LIVEKIT_URL=${LIVEKIT_URL:-ws://livekit:7880}
      - LIVEKIT_HOST=${LIVEKIT_URL:-ws://livekit:7880}
      - LIVEKIT_API_KEY=${LIVEKIT_API_KEY:-devkey}
      - LIVEKIT_API_SECRET=${LIVEKIT_API_SECRET:-secret}
      - LIVEKIT_AGENT_PORT=${LIVEKIT_AGENT_PORT:-7880}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-no-key-needed}
      - GROQ_API_KEY=${GROQ_API_KEY:-no-key-needed}
      - STT_PROVIDER=${STT_PROVIDER:-parakeet}
      - TTS_PROVIDER=${TTS_PROVIDER:-kokoro}
    depends_on:
      livekit:
        condition: service_started
      kokoro:
        condition: service_started
      soprano:
        condition: service_started
      whisper:
        condition: service_started
      parakeet:
        condition: service_healthy
      vllm:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:8081/ > /dev/null"]
      interval: 5s
      timeout: 3s
      retries: 5
      start_period: 10s
    networks:
      - agent_network

  frontend:
    build:
      context: ./frontend
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_LIVEKIT_URL=ws://localhost:7880
      - LIVEKIT_URL=ws://livekit:7880
      - LIVEKIT_API_KEY=devkey
      - LIVEKIT_API_SECRET=secret
    depends_on:
      livekit:
        condition: service_started
    networks:
      - agent_network

volumes:
  whisper-data:
  parakeet-data:
  soprano-data:
  vllm-data:

networks:
  agent_network:
    driver: bridge
