# macOS note: vLLM requires an NVIDIA GPU and is not supported on macOS Docker.
# To use this project on macOS, point VLLM_BASE_URL to an external
# OpenAI-compatible endpoint (e.g. a remote vLLM or llama.cpp server)
# and remove the vllm service dependency from the livekit_agent service.
services: {}
